## 背景
[Apache-Atlas](https://atlas.apache.org/#/)是一个比较流行的做数据治理的开源项目。然而，现在的中文博客，大多是介绍它的概况和功能，并没有比较完备的中文文档，详细分析它的设计和实现。这个系列会结合一部分源码，更深入的分析这个项目。

## 动机
大数据在经历了几年的野蛮生长后，涌现出了种类繁多的数据系统。这些数据系统，大多是特别擅长解决某一类特定的问题，理论上不可能有一套系统，可以完美的解决所有大数据的应用场景。举个例子，HDFS可以无限扩展，存储廉价，吞吐量大，但是不支持低延时的访问，因此适合做离线数据的存储。而Kafka，针对顺序的写入和读取做了大量的优化，性能非常好，但是当集群规模过大时，可维护性变得很差，所以通常被用来暂存流式数据。所以，公司内部使用各种各样的数据系统，解决各种各样的大数据业务场景，是必然的。

那么，与以往普通业务数据都放在统一的关系型数据中不同，大数据以不同的格式，不同的生命周期，不同的schema，散落在不同的数据系统中。这带来了以下的问题：
* 数据产生价值的开销很大：数据的metadata的离散性，决定了数据使用者很难找到对自己真正有价值的数据。
* 资源的冗余：对于数据全局视野的缺失，决定了很多团队可能对同一份数据做了同样的处理，消耗了同样的计算和存储。
* 数据的安全性难以控制：每个离散的数据系统拥有自己独立auth&auth，数据的管理者难以定义清晰的规则，控制数据的访问性，也不能安全的共享数据。

Apache-Atlas正是用来解决这些问题的。

## 功能
### 统一的metadata管理
Atlas定义了一套数据模型，可以用来有效的建模数据的元数据，具体来说：
* 定义了一组预定义数据类型，用来建模数据的元数据。
* 用户可以自定义数据类型，来建模自己的元数据。




